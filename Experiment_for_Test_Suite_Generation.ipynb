{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYLH44UBolV_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def calculate_entropy_features(file_bytes):\n",
        "    \"\"\"\n",
        "    Calculate Shannon and Rényi entropy from byte data.\n",
        "    \"\"\"\n",
        "    byte_counts = [0] * 256\n",
        "    for b in file_bytes:\n",
        "        byte_counts[b] += 1\n",
        "    total_bytes = len(file_bytes)\n",
        "    probabilities = [count / total_bytes for count in byte_counts if count > 0]\n",
        "\n",
        "    # Shannon Entropy (F1)\n",
        "    shannon_entropy = -sum(p * math.log2(p) for p in probabilities)\n",
        "\n",
        "    # Rényi Entropy (F2) with alpha = 2\n",
        "    alpha = 2\n",
        "    renyi_entropy = 1 / (1 - alpha) * math.log2(sum(p ** alpha for p in probabilities))\n",
        "\n",
        "    return shannon_entropy, renyi_entropy\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess dataset by removing entropy outliers (IQR method) and normalizing features.\n",
        "    \"\"\"\n",
        "    for col in ['shannon', 'renyi']:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        df = df[(df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)]\n",
        "\n",
        "    df[['shannon', 'renyi']] = (df[['shannon', 'renyi']] - df[['shannon', 'renyi']].min()) / \\\n",
        "                               (df[['shannon', 'renyi']].max() - df[['shannon', 'renyi']].min())\n",
        "    return df\n",
        "\n",
        "\n",
        "def evaluate_models(df):\n",
        "    \"\"\"\n",
        "    Evaluate ML models using Shannon and Rényi entropy with 5-fold stratified CV.\n",
        "    Returns confusion matrix results and passing rate analysis.\n",
        "    \"\"\"\n",
        "    results_confusion = []\n",
        "    results_passing = []\n",
        "\n",
        "    y = df['label'].values\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    models = {\n",
        "        'NB': GaussianNB(),\n",
        "        'RF': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'DT': DecisionTreeClassifier(random_state=42)\n",
        "    }\n",
        "\n",
        "    for entropy_name, feature in [('F1', 'shannon'), ('F2', 'renyi')]:\n",
        "        X = df[[feature]].values\n",
        "\n",
        "        for model_name, model in models.items():\n",
        "            tp_total = tn_total = fp_total = fn_total = 0\n",
        "\n",
        "            for train_idx, test_idx in skf.split(X, y):\n",
        "                X_train, X_test = X[train_idx], X[test_idx]\n",
        "                y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "\n",
        "                cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "                if cm.shape == (2, 2):\n",
        "                    tn, fp, fn, tp = cm.ravel()\n",
        "                else:\n",
        "                    tn = fp = fn = tp = 0\n",
        "\n",
        "                tp_total += tp\n",
        "                tn_total += tn\n",
        "                fp_total += fp\n",
        "                fn_total += fn\n",
        "\n",
        "            results_confusion.append({\n",
        "                'Entropy': entropy_name,\n",
        "                'Model': model_name,\n",
        "                'TP': tp_total,\n",
        "                'TN': tn_total,\n",
        "                'FP': fp_total,\n",
        "                'FN': fn_total\n",
        "            })\n",
        "\n",
        "\n",
        "            total_decisions = tp_total + tn_total + fp_total + fn_total\n",
        "            true_accepts = tp_total + tn_total\n",
        "            passing_rate = (true_accepts / total_decisions) * 100\n",
        "\n",
        "            results_passing.append({\n",
        "                'Feature + Model Configuration': f\"{entropy_name} + {model_name}\",\n",
        "                'TD': total_decisions,\n",
        "                'TA': true_accepts,\n",
        "                'Passing Rate': f\"{passing_rate:.2f}%\"\n",
        "            })\n",
        "\n",
        "    df_confusion = pd.DataFrame(results_confusion)\n",
        "    df_passing = pd.DataFrame(results_passing)\n",
        "    return df_confusion, df_passing\n",
        "\n",
        "# ------------------------ Main Execution ------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # STEP 1: Load CSV (user must ensure shannon, renyi, label exist)\n",
        "    df = pd.read_csv(\"your_entropy_dataset.csv\")  # Replace with real file path\n",
        "\n",
        "    # STEP 2: Preprocess entropy values\n",
        "    df = preprocess_data(df)\n",
        "\n",
        "    # STEP 3: Evaluate classifiers\n",
        "    confusion_df, passing_df = evaluate_models(df)\n",
        "\n",
        "    # STEP 4: Print formatted results\n",
        "    print(\"=== Confusion Matrix Results ===\\n\")\n",
        "    print(confusion_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n=== Passing Rate Analysis ===\\n\")\n",
        "    print(passing_df.to_string(index=False))\n",
        "\n",
        "    # STEP 5 (optional): Save to CSV for manuscript integration\n",
        "    confusion_df.to_csv(\"confusion_matrix_results.csv\", index=False)\n",
        "    passing_df.to_csv(\"passing_rate_results.csv\", index=False)\n",
        "\n",
        "    # Note: Our test suite generation for edge-case files was performed by mapping\n",
        "    # actual predictions to expected outcomes using the confusion matrix based on our methodology.\n",
        "\n",
        "    # Note: This code represents experiments for document-based files.\n",
        "    # Identical methodology was applied independently for image-based, compressed,\n",
        "    # and other file formats using their respective entropy features and labels.\n"
      ]
    }
  ]
}